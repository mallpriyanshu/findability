{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between Findability and Retrievability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "import csv\n",
    "import scipy\n",
    "import rbo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./Findability-experiments/Robust04/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_robust04 = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/allrd_robust04.pickle', 'rb') as f:\n",
    "    allrd_robust04 = pickle.load(f)\n",
    "    \n",
    "with open('./Findability-experiments/WT10g/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_wt10g = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/allrd_WT10g.pickle', 'rb') as f:\n",
    "    allrd_wt10g = pickle.load(f)\n",
    "\n",
    "with open('./Findability-experiments/MSMARCO/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_msmarco = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/allrd_MSMARCO.pickle', 'rb') as f:\n",
    "    allrd_msmarco = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson's Correlation Coefficient calculation\n",
      "\n",
      "For Robust04, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = -0.0944\t\tp-value = 0.0\n",
      "For WT10g, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = -0.0088\t\tp-value = 8.369595764235922e-30\n",
      "For MSMARCO, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = 0.0115\t\tp-value = 5.766135566854784e-250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nPearson's Correlation Coefficient calculation\\n\")\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'Robust04'\n",
    "fd = fd_robust04\n",
    "rd = dict(allrd_robust04['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'WT10g'\n",
    "fd = fd_wt10g\n",
    "rd = dict(allrd_wt10g['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'MSMARCO'\n",
    "fd = fd_msmarco\n",
    "rd = dict(allrd_msmarco['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kendall Rank Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kendall's Correlation Coefficient calculation\n",
      "\n",
      "For Robust04, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = -0.0518\t\tp-value = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5218: RuntimeWarning: overflow encountered in long_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For WT10g, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = 0.0084\t\tp-value = 2.1520587221635985e-57\n",
      "For MSMARCO, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = 0.0307\t\tp-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nKendall's Correlation Coefficient calculation\\n\")\n",
    "\n",
    "###########################################\n",
    "\n",
    "corpus = 'Robust04'\n",
    "fd = fd_robust04\n",
    "rd = dict(allrd_robust04['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'WT10g'\n",
    "fd = fd_wt10g\n",
    "rd = dict(allrd_wt10g['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'MSMARCO'\n",
    "fd = fd_msmarco\n",
    "rd = dict(allrd_msmarco['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Retrievability on Findability's Known-item queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Findability-experiments/Robust04/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_robust04 = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/Known-item-queries-rd/allrd_Robust04.pickle', 'rb') as f:\n",
    "    allrd_robust04 = pickle.load(f)\n",
    "\n",
    "with open('./Findability-experiments/WT10g/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_wt10g = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/Known-item-queries-rd/allrd_WT10g.pickle', 'rb') as f:\n",
    "    allrd_wt10g = pickle.load(f)\n",
    "\n",
    "with open('./Findability-experiments/MSMARCO/fd_bm25_1.20_0.75.pickle', 'rb') as f:\n",
    "    fd_msmarco = pickle.load(f)\n",
    "\n",
    "with open('./Retrievability-experiments/Known-item-queries-rd/allrd_MSMARCO.pickle', 'rb') as f:\n",
    "    allrd_msmarco = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson's Correlation Coefficient calculation\n",
      "\n",
      "For Robust04, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = -0.1292\t\tp-value = 0.0\n",
      "For WT10g, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = -0.0256\t\tp-value = 2.1440237772913133e-238\n",
      "For MSMARCO, Findability f(d) vs Retrievability r(d) for c = 100:\t rho = 0.0388\t\tp-value = 0.0\n",
      "\n",
      "Kendall's Correlation Coefficient calculation\n",
      "\n",
      "For Robust04, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = -0.1053\t\tp-value = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py:5218: RuntimeWarning: overflow encountered in long_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For WT10g, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = -0.0287\t\tp-value = 0.0\n",
      "For MSMARCO, Findability f(d) vs Retrievability r(d) for c = 100:\t tau = 0.0269\t\tp-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPearson's Correlation Coefficient calculation\\n\")\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'Robust04'\n",
    "fd = fd_robust04\n",
    "rd = dict(allrd_robust04['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'WT10g'\n",
    "fd = fd_wt10g\n",
    "rd = dict(allrd_wt10g['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "\n",
    "corpus = 'MSMARCO'\n",
    "fd = fd_msmarco\n",
    "rd = dict(allrd_msmarco['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Pearson's correlation computation\n",
    "rho, pval = scipy.stats.pearsonr(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t rho = {rho:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "print(\"\\nKendall's Correlation Coefficient calculation\\n\")\n",
    "\n",
    "###########################################\n",
    "\n",
    "corpus = 'Robust04'\n",
    "fd = fd_robust04\n",
    "rd = dict(allrd_robust04['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "###########################################\n",
    "\n",
    "corpus = 'WT10g'\n",
    "fd = fd_wt10g\n",
    "rd = dict(allrd_wt10g['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')\n",
    "\n",
    "###########################################\n",
    "\n",
    "corpus = 'MSMARCO'\n",
    "fd = fd_msmarco\n",
    "rd = dict(allrd_msmarco['rd_bm25_100'])\n",
    "\n",
    "common_lucenepageids = set(fd) & set(rd)\n",
    "fd_list, rd_list = [], []\n",
    "for pageid in sorted(common_lucenepageids):\n",
    "    fd_list.append(fd[pageid])\n",
    "    rd_list.append(rd[pageid])\n",
    "fd_list, rd_list = zip(*sorted(zip(fd_list,rd_list), reverse=True))\n",
    "# Kendall's correlation computation\n",
    "corr, pval = scipy.stats.kendalltau(fd_list, rd_list)\n",
    "print(f'For {corpus}, Findability f(d) vs Retrievability r(d) for c = 100:\\t tau = {corr:.4f}\\t\\tp-value = {pval}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
